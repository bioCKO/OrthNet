#!/usr/bin/env python
import sys, os, math, argparse
from argparse import RawTextHelpFormatter

		
###################################################
### 0. script description and parsing arguments ###
###################################################
synopsis1 = "\
  find OrthNets that are either exactly the same or similar topology\n\
  with a query OrthNet in .sif format."
synopsis2 = "detailed description:\n\
 1. Input files:\n\
  - './<Project>.list' including all species IDs (spcsIDs), one per line,\n\
     that appear in OrthNets.\n\
  - <OrthNet.sif> includes multiple OrthNets to be clustered, the entire\n\
     OrthNets, or a subset of them, generated by 'format_OrthNetEdges_4SIF.py';\n\
  - <OrthNet.sif> is node1, edge, node2, and OrthNetID, tab-delimited;\n\
     node1 and node2 are formatted 'spcsID|geneID'; \n\
     edge={cl, cl_rc, tr, tr_rc, nd, nd_rc, TD_rc};\n\
     <OrthNet.sif> is sorted based on OrthNetID (the 4th column)\n\
 2. Output files and options:\n\
  - '<Project>.OrthNets_exact_topology.summary.txt' contains all OrthNetIDs\n\
     among <OrthNet.sif> with the exact topology and edge types, one cluster\n\
     per line; node copy numbers and OrthNet_topology_str are also printed;\n\
  - '<Project>.OrthNets_exact_topology.clusterID.list' contains all OrthNetIDs\n\
     and cluster IDs, tab-delimited and one OrthNet per line;\n\
  - '-o Path2Output': path to other output files (dafault='.'). \n\
  - '-s': print a shorter version of summary, without printing OrthNet IDs in\n\
     each cluster (default=False).\n\
  - '-e': print node copy numbers for each species separately; also print all\n\
     OrthNets with unique topologies (singlets); for singlets, print OrthNetID\n\
     instead of a cluster ID (default=False).\n\
  - '-r': print the edge score used for ranking paralogs (default=False).\n\
 by ohdongha@gmail.com ver0.5.2 20181211\n"
 
#version_history
#20181211 ver 0.5.2 -e option added, to facilitate analyses based on nodeCN
#20181205 ver 0.5.1 -r option default is now False
#20181030 ver 0.5 consider incoming edges as well when ranking paralogs
#20181016 ver 0.4 introduced "ON_topology_str2" for more human-readable summary of the OrthNet topology
#20180928 ver 0.3 modified to 'cluster_OrthNets_topology_exact.py'
#20180927 ver 0.2 modified to 'search_OrthNet_topology_exact.py'
#20180419 ver 0.1 modified to work with combined CLfm results and accept node copy number information separately, rather than as part of the regular expression query
#20161026 ver 0.0 formerly 'search_OrthNet.py'
  
parser = argparse.ArgumentParser(description = synopsis1, epilog = synopsis2, formatter_class = RawTextHelpFormatter)

# edge weight parameters for scoring paralogs in an OrthNet (change these as needed)
edgeWeight1_dict = { "TD":11, "cl":7, "tr":5, "nd":3 } # prime numbers for ranking paralogs, don't need to be the same to edge weights for MCL
edgeWeight2_dict = { "TD_rc":'T', "cl_rc":'d', "cl":'c', "tr_rc":'u', "tr":'t', "nd_rc":'o', "nd":'n' } # human-readable edgeType code; added in ver 0.4

# positional arguments
parser.add_argument('Project', type=str, help="'./<Project>.list' includes spcsIDs being compared")
parser.add_argument('OrthNet', type=str, help="OrthNets in .sif format; see below")
# options and parameters
parser.add_argument('-o', dest="Path2Output", type=str, default=".", help="PATH for temporary and output files")
parser.add_argument('-s', dest="short_summary", action="store_true", default=False) 
parser.add_argument('-e', dest="print_each", action="store_true", default=False) 
parser.add_argument('-r', dest="print_rank", action="store_true", default=False) 
#parser.add_argument('-f', dest="filter_nodeCN", type=str, default="NA", help="see below")  # for future use

args = parser.parse_args()

# defining PATHs and create Output directory, if not already exisiting
path_output = args.Path2Output
if path_output[-1] != "/": path_output = path_output + "/"

try: 
	os.makedirs(path_output)
except OSError:
	if not os.path.isdir(path_output): raise


##############################################
### 1. reading spcsID and parsing OrthNets ###
##############################################
### 1.1 reading fin_SpcsList
try:
	fin_SpcsList = open(args.Project + '.list', 'r')
except IOError:
	fin_SpcsList = open(args.Project, 'r')
print "\nreading the species/genome list file: " + fin_SpcsList.name

spcsID_list = []
for line in fin_SpcsList:
	spcsID_list.append(line.strip())
	print line.strip()
fin_SpcsList.close()
print "Total %d species/genome IDs detected." % (len(spcsID_list))


### 1.2 parsing the OrthNet file - ranking paralogs and flattening nodeIDs
try:
	fin_OrthNet = open(args.OrthNet, 'r')
except IOError:
	fin_OrthNet = open(args.OrthNet + '.sif', 'r')

print "Reading the OrthNet OrthNets from %s" % fin_OrthNet.name

ON_nodeCN_dict = dict() # key = OrthNetID, value = ON_num_paralog (list)
ON_flattened_ndID_dict = dict() # key = OrthNetID, value = dict. with key = spcsID, value = dict. with key = nodeID, value = flattened_nodeID
ON_scOut_nd_dict = dict() # key = OrthNetID, value = dict. with key = spcsID, value = dict. with key = nodeID, value = edgeWeight1 for all OUTGOING edges multiplied
ON_scIn_nd_dict = dict() # key = OrthNetID, value = dict. with key = spcsID, value = dict. with key = nodeID, value = edgeWeight1 for all INCOMING edges multiplied
ON_scAll_nd_dict = dict() # key = OrthNetID, value = dict. with key = spcsID, value = dict. with key = nodeID, value = scIn * 2 + scOut

ONid = ""
ONid_prev = ""
start = True

for line in fin_OrthNet: 
	tok = line.split('\t')
	ONid = tok[3].strip()
	if ONid != ONid_prev:
		if start:
			start = False
		else:
			## process the **previous** OrthNet
			# get nodeCN
			ON_num_paralog = []
			for s in spcsID_list:
				ON_num_paralog.append( len( ON_scOut_nd_dict[ONid_prev][s] ) )
			ON_nodeCN_dict[ONid_prev] = ON_num_paralog

			# get scAll for all nodes
			for s in spcsID_list:
				for nd in ON_scOut_nd_dict[ONid_prev][s]:
#					ON_scAll_nd_dict[ONid_prev][s][nd] = ON_scOut_nd_dict[ONid_prev][s].get(nd,1) + ON_scIn_nd_dict[ONid_prev][s].get(nd,1) * 2
					ON_scAll_nd_dict[ONid_prev][s][nd] = ON_scOut_nd_dict[ONid_prev][s][nd] + ON_scIn_nd_dict[ONid_prev][s][nd] * 2

			# get flattened_ndID					
			digit_for_num_parlog = int( math.log(max( ON_num_paralog ),10) ) + 1
			for s in spcsID_list:
				i = 0
				for ndID, scr in sorted(ON_scAll_nd_dict[ONid_prev][s].iteritems(), key=lambda (k,v):(v,k), reverse=True):
					i += 1
					ON_flattened_ndID_dict[ONid_prev][s][ndID] = s + ';' + str( i ).rjust(digit_for_num_parlog, '0')

		# and initialize
		ONid_prev = ONid
		ON_flattened_ndID_dict[ONid] = dict() # key = dict. with spcsID (for query node or nd1), value = dict. with nodeID, value = flattened_nodeID
		ON_scOut_nd_dict[ONid] = dict() # dict. with key = spcsID (for query node or nd1), value = dict. with key = nodeID, value = edgeWeight1 for all OUTGOING edges multiplied 
		ON_scIn_nd_dict[ONid] = dict() # dict. with key = spcsID (for query node or nd1), value = dict. with key = nodeID, value = edgeWeight1 for all INCOMING edges multiplied 
		ON_scAll_nd_dict[ONid] = dict() # dict. with key = spcsID (for query node or nd1), value = dict. with key = nodeID, value = scIn * 2 + scOut
		for s in spcsID_list:
			ON_scOut_nd_dict[ONid][s] = dict() # ON_scOut_nd_dict[ONid][spcsID][nodeID] = edgeWeight1 for all OUTGOING edges multiplied
			ON_scIn_nd_dict[ONid][s] = dict() # ON_scOut_nd_dict[ONid][spcsID][nodeID] = edgeWeight1 for all INCOMING edges multiplied
			ON_scAll_nd_dict[ONid][s] = dict() # ON_scOut_nd_dict[ONid][spcsID][nodeID] = scIn * 2 + scOut
			ON_flattened_ndID_dict[ONid][s] = dict() # ON_flattened_ndID_dict[ONid][spcsID][nodeID] = flattened_nodeID
		
	# within the same OrthNet, scoring nodes
	nd1 = tok[0]
	edgeType = tok[1]
	nd2 = tok[2]
	edgeWeight = 0
	if edgeType != '-':
		edgeWeight = edgeWeight1_dict[ edgeType.replace("_rc", "") ]
		ON_scOut_nd_dict[ONid][nd1.split('|')[0]][nd1] = ON_scOut_nd_dict[ONid][nd1.split('|')[0]].get(nd1, 1) * edgeWeight
		ON_scOut_nd_dict[ONid][nd2.split('|')[0]][nd2] = ON_scOut_nd_dict[ONid][nd2.split('|')[0]].get(nd2, 1) # in case a node is only at the receiving end of a unidirectional edge
		ON_scIn_nd_dict[ONid][nd2.split('|')[0]][nd2] = ON_scIn_nd_dict[ONid][nd2.split('|')[0]].get(nd2, 1) * edgeWeight
		ON_scIn_nd_dict[ONid][nd1.split('|')[0]][nd1] = ON_scIn_nd_dict[ONid][nd1.split('|')[0]].get(nd1, 1) # in case a node is only at the giving end of a unidirectional edge
		if edgeType.endswith("_rc"): # if the edge is reciprocal, add the same values with nd1 and nd2 switched
			ON_scOut_nd_dict[ONid][nd2.split('|')[0]][nd2] = ON_scOut_nd_dict[ONid][nd2.split('|')[0]].get(nd2, 1) * edgeWeight 
			ON_scIn_nd_dict[ONid][nd1.split('|')[0]][nd1] = ON_scIn_nd_dict[ONid][nd1.split('|')[0]].get(nd1, 1) * edgeWeight 

## process the ** last ** OrthNet
ON_num_paralog = []
for s in spcsID_list:
	ON_num_paralog.append( len( ON_scOut_nd_dict[ONid_prev][s] ) )
ON_nodeCN_dict[ONid_prev] = ON_num_paralog

for s in spcsID_list:
	for nd in ON_scOut_nd_dict[ONid_prev][s]:
#		ON_scAll_nd_dict[ONid_prev][s][nd] = ON_scOut_nd_dict[ONid_prev][s].get(nd,1) + ON_scIn_nd_dict[ONid_prev][s].get(nd,1) * 2
		ON_scAll_nd_dict[ONid_prev][s][nd] = ON_scOut_nd_dict[ONid_prev][s][nd] + ON_scIn_nd_dict[ONid_prev][s][nd] * 2

digit_for_num_parlog = int( math.log(max( ON_num_paralog ),10) ) + 1
for s in spcsID_list:
	i = 0
	for ndID, scr in sorted(ON_scAll_nd_dict[ONid_prev][s].iteritems(), key=lambda (k,v):(v,k), reverse=True):
		i += 1
		ON_flattened_ndID_dict[ONid_prev][s][ndID] = s + ';' + str( i ).rjust(digit_for_num_parlog, '0')

			
### 1.3 parsing the OrthNet file - edgeSummary (human-readable) for each node # added in ver. 0.4
ON_edgeSummary_dict = dict() # key = nodeID + "_in_" + OrthNetID, value = dict. of edgeTypes with key = spcsID of the target node, value = list of edgeType for each paralog in target spcsID;
			
# reading fin_OrthNet again
fin_OrthNet.seek(0) # read the file once again
ONid = ""
nd1 = ""
nd2 = ""
nd1_flat = ""
nd2_flat = ""
edgeType = ""

for line in fin_OrthNet:
	tok = line.split('\t')
	nd1 = tok[0].strip()
	edgeType = tok[1].strip()
	nd2 = tok[2].strip()
	ONid = tok[3].strip()

	# initializing ON_edgeSummary_dict for each node at its first appearance
	if ( nd1 + "_in_" + ONid ) not in ON_edgeSummary_dict:
#		ON_edgeSummary_dict[ nd1 + "_in_" + ONid ] = ON_edgeSummaryFormat_dict[ONid]  #### beware!! this does not work!!!; either use copy.deepcopy() or explicitly declare the new dict. structure,
		ON_edgeSummary_dict[ nd1 + "_in_" + ONid ] = dict()
		for s in spcsID_list:	# iterate over spcsIDs
			ON_edgeSummary_dict[ nd1 + "_in_" + ONid ][s] = ['-'] * ON_nodeCN_dict[ONid][spcsID_list.index(s)]
	if ( nd2 + "_in_" + ONid ) not in ON_edgeSummary_dict:
		ON_edgeSummary_dict[ nd2 + "_in_" + ONid ] = dict()
		for s in spcsID_list:	# iterate over spcsIDs
			ON_edgeSummary_dict[ nd2 + "_in_" + ONid ][s] = ['-'] * ON_nodeCN_dict[ONid][spcsID_list.index(s)]
	
	# processing each edge
	if edgeType != '-':
		nd1_flat = ON_flattened_ndID_dict[ONid][nd1.split('|')[0]][nd1] # e.g. Aly;01, Aly;02, ..., Aly;10 # ';' is used as a temporary separator
		nd2_flat = ON_flattened_ndID_dict[ONid][nd2.split('|')[0]][nd2]
				
#		print "nd1=%s nd2=%s nd1_flat=%s nd2_flat=%s ON_edgeSummary_dict[%s][%s] --- %d == %s" % ( nd1, nd2, nd1_flat, nd2_flat, nd1 + "_in_" + ONid, nd2_flat.split(';')[0], int(nd2_flat.split(';')[1]) - 1, edgeWeight2_dict[ edgeType ]) # for debuggin
		ON_edgeSummary_dict[ nd1 + "_in_" + ONid ][ nd2_flat.split(';')[0] ][ int(nd2_flat.split(';')[1]) - 1 ] = edgeWeight2_dict[ edgeType ]
		if edgeType.endswith("_rc"): # for reciprocal edges, add edgeType code ( == edgeWeight2_dict[ edgeType ] ) the other way around, too.
			ON_edgeSummary_dict[ nd2 + "_in_" + ONid ][ nd1_flat.split(';')[0] ][ int(nd1_flat.split(';')[1]) - 1 ] = edgeWeight2_dict[ edgeType ]

print "finished reading and parsing OrthNets," 


### 1.4 construct ON_topology_str_dict and ON_topology_str2_dict # added in ver. 0.4 # modified in ver. 0.5
ON_topology_str_dict = dict() # key = OrthNetID, value = ON_toplogy_str based on edgeWeight1_dict, which was used for ranking paralogs 
ON_topology_str = "" # e.g. "Aly1:-|d|d|d.t.t|c_Ath1: ..."

ON_topology_str2_dict = dict() # key = OrthNetID; value = ON_topology_str2, which contains flattened_ndID + ":" + edgeSummary_str for all nodes; added in ver. 0.4
ON_topology_str2 = "" # e.g. "Aly1:-|d|d|d.t.t|c_Ath1: ..."
edgeSummary_str = "" # e.g. "-|d|d|d,t,t|t|c"

for ONid in ON_flattened_ndID_dict:
	ON_topology_str = ""
	ON_topology_str2 = ""
	
	for s1 in spcsID_list: # iterate over query node species
		for ndID, ndIDf in sorted(ON_flattened_ndID_dict[ONid][s1].iteritems(), key=lambda (k,v):(v,k)):
			# process ON_toplogy_str
			if ON_topology_str == "":
				ON_topology_str = "%s:%d" % ( ndIDf.replace(';', ''), ON_scAll_nd_dict[ONid][ndID.split('|')[0]].get(ndID, 1) ) 
			else:
				ON_topology_str = ON_topology_str + ",%s:%d" % ( ndIDf.replace(';', ''), ON_scAll_nd_dict[ONid][ndID.split('|')[0]].get(ndID, 1) ) 			

			# process ON_toplogy_str2				
			edgeSummary_str = ""
			for s2 in spcsID_list: # iterate over target node species, assemblying edgeSummary_str for each query node
				if edgeSummary_str == "":
					edgeSummary_str = ''.join( ON_edgeSummary_dict[ ndID + "_in_" + ONid ][ s2 ] )				
				else:
					edgeSummary_str = edgeSummary_str + ',' + ''.join( ON_edgeSummary_dict[ ndID + "_in_" + ONid ][ s2 ] )
					
#			print "ONid = %s, ndID = %s, ndIDf = %s, edgeSummary_str = %s" % (ONid, ndID, ndIDf, edgeSummary_str) # for debugging
#			print "edgeSummary_dict for %s = " % (ndID + "_in_" + ONid) # for debugging
#			print ON_edgeSummary_dict[ ndID + "_in_" + ONid ] # for debugging
			
			if ON_topology_str2 == "":
				ON_topology_str2 = ndIDf.replace(';', '') + ':' + edgeSummary_str
			else:
				ON_topology_str2 = ON_topology_str2 + "|" + ndIDf.replace(';', '') + ':' + edgeSummary_str
		
	ON_topology_str_dict[ONid] = ON_topology_str		
	ON_topology_str2_dict[ONid] = ON_topology_str2

print "finished transforming OrthNets to topology strings," 


##############################
### 2. clustering OrthNets ###
##############################
### 2.1 identifying singlets based on nodeCN
l = ON_nodeCN_dict.values()
singlets_list = [ONid for ONid in ON_nodeCN_dict if l.count(ON_nodeCN_dict[ONid]) == 1]
ON2bClusterd_list = [ONid for ONid in ON_nodeCN_dict if l.count(ON_nodeCN_dict[ONid]) > 1]

### 2.2 clustering non-singlets
clstrd_topology_dict = dict() # key = ON_topology_str, value = numerical clusterID (cID)
clstrd_ONid_dict = dict() # key = numerical cID, value = list of OrthNet IDs in the cluster
clstr_size_dict = dict() # key = cID, value = number of ONid in each cluster
cID = 0

for ONid in ON2bClusterd_list:
	#if ON_topology_str_dict[ONid] not in clstrd_topology_dict:
	if ON_topology_str2_dict[ONid] not in clstrd_topology_dict:
		cID += 1
		#clstrd_topology_dict[ ON_topology_str_dict[ONid] ] = cID
		clstrd_topology_dict[ ON_topology_str2_dict[ONid] ] = cID # ver 0.4; let's try clustering based on ON_toplogy_str2
		clstrd_ONid_dict[ cID ] = [ ONid ]
	else:
#		clstrd_ONid_dict[ clstrd_topology_dict[ ON_topology_str_dict[ONid] ] ].append( ONid )
		clstrd_ONid_dict[ clstrd_topology_dict[ ON_topology_str2_dict[ONid] ] ].append( ONid )

for cID in clstrd_ONid_dict:
	clstr_size_dict[ cID ] = len( clstrd_ONid_dict[cID] )

try:
	digit_for_new_cID = int( math.log( len( clstrd_ONid_dict ), 10) ) + 1
except ValueError:
	print "ValueError, for some reason..."
	digit_for_new_cID = 1

print "finished clustering OrthNets based on topology strings," 


#######################################################################
### 3. Print results of clustering OrthNets based on topology_exact ###
#######################################################################	
## open output files
projectID = os.path.splitext( os.path.basename( args.Project ) )[0]
fout_summary = open( path_output + projectID + ".OrthNets_exact_topology.summary.txt", 'w') 
fout_list = open( path_output + projectID + ".OrthNets_exact_topology.clusterID.list", 'w') 
fout_log = open( path_output + projectID + ".OrthNets_exact_topology.log", 'w') 


### 3.1 print a summary of clusters ( + assign new_cID to each ONid)
## print the header to .summary.txt
if args.print_each:
	str_header = "cID\tocc_topology\tocc_nodeCN\tnum_nodes\t"
	for s in spcsID_list:
		str_header = str_header + s + '\t'
	str_header = str_header + "nodeCN\ttopology"
else:
	str_header = "cID\tocc_topology\tocc_nodeCN\tnum_nodes\tnodeCN\ttopology"
if args.print_rank:
	str_header = str_header + "\ttopology_rank"
if args.short_summary == False:
	str_header = str_header + "\tONid"
fout_summary.write(str_header + '\n')

## print the summary
new_cID_dict = dict() # key = ONid, value = new_cID_formatted
str2bPrinted = ""
new_cID = 0
for cID, cSize in sorted(clstr_size_dict.iteritems(), key=lambda (k,v):(v,k), reverse=True):
	new_cID += 1
	
	# get total num_nodes for each cID
	num_nodes = 0
	for n in ON_nodeCN_dict[ clstrd_ONid_dict[cID][0] ]:
		num_nodes += n
		
	# printing the summary to .summary.txt
	str2bPrinted = "%s\t%d\t%d\t%d" % ( 'c' + str( new_cID ).rjust(digit_for_new_cID, '0'), \
							cSize, \
							ON_nodeCN_dict.values().count(ON_nodeCN_dict[ clstrd_ONid_dict[cID][0] ] ), \
							num_nodes )
	if args.print_each:
		str2bPrinted = str2bPrinted + '\t' + '\t'.join( str(n) for n in ON_nodeCN_dict[ clstrd_ONid_dict[cID][0] ] )
	str2bPrinted = str2bPrinted + '\t' + '.'.join( str(n) for n in ON_nodeCN_dict[ clstrd_ONid_dict[cID][0] ] )			
	if args.print_rank:
		str2bPrinted = str2bPrinted + "\t%s\t%s" % ( ON_topology_str2_dict[ clstrd_ONid_dict[cID][0] ], \
								ON_topology_str_dict[ clstrd_ONid_dict[cID][0] ] )
	else:
		str2bPrinted = str2bPrinted + "\t%s" % ( ON_topology_str2_dict[ clstrd_ONid_dict[cID][0] ] )
	if args.short_summary == False:
		str2bPrinted = str2bPrinted + '\t' + '|'.join( clstrd_ONid_dict[cID] )
	fout_summary.write( str2bPrinted + '\n')

	# mapping the ONid : new_cID_formatted 							
	for ONid in sorted(clstrd_ONid_dict[cID]):
		new_cID_dict[ ONid ] = 'c' + str( new_cID ).rjust(digit_for_new_cID, '0')

## print singlets if args.each
if args.print_each:
	for ONid in singlets_list:
		num_nodes = 0
		for n in ON_nodeCN_dict[ ONid ]:
			num_nodes += n

		str2bPrinted = "%s\t%d\t%d\t%d" % ( ONid, 1, ON_nodeCN_dict.values().count(ON_nodeCN_dict[ ONid ] ), num_nodes )
		str2bPrinted = str2bPrinted + '\t' + '\t'.join( str(n) for n in ON_nodeCN_dict[ ONid ] )
		str2bPrinted = str2bPrinted + '\t' + '.'.join( str(n) for n in ON_nodeCN_dict[ ONid ] )
		if args.print_rank:
			str2bPrinted = str2bPrinted + "\t%s\t%s" % ( ON_topology_str2_dict[ ONid ], \
									ON_topology_str_dict[ ONid ] )
		else:
			str2bPrinted = str2bPrinted + "\t%s" % ( ON_topology_str_dict[ ONid ] )
		if args.short_summary == False:
			str2bPrinted = str2bPrinted + '\t' + ONid
		fout_summary.write( str2bPrinted + '\n')

### 3.1 print the ONid - new_cID_formatted list
# print the header to .clusterID.list
fout_list.write( "ONid\tcID\n" )
for ONid, new_cID_formatted in sorted(new_cID_dict.iteritems(), key=lambda (k,v):(v,k), reverse=False):
	fout_list.write( "%s\t%s\n" % (ONid, new_cID_formatted ) )

#print "singlets: %s" % ' '.join( sorted(singlets_list) )
fout_log.write( "Input .sif file = %s\n" % fin_OrthNet.name)
fout_log.write( "Output .summary.txt file = %s\n" % fout_summary.name)
fout_log.write( "Output .clusterID.list file = %s\n" % fout_list.name)
fout_log.write( "Out of total %d OrthNets, %d were grouped into %d clusters, based on exact topology matches.\n" % (len(ON_nodeCN_dict), len(ON_nodeCN_dict) - len(singlets_list), len(clstrd_ONid_dict) ) )
fout_log.write( "Out of total %d OrthNets, %d were singlets based on node copy numbers.\n" % (len(ON_nodeCN_dict), len(singlets_list) ) )

print "finished printing results to %s" % path_output
print "done"
fin_OrthNet.close()
fout_summary.close()
fout_list.close()
fout_log.close()